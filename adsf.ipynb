{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'company': {'train': <torch.utils.data.dataloader.DataLoader object at 0x000001D4F36E2EB0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x000001D4F38A6EE0>}, 'brand': {'train': <torch.utils.data.dataloader.DataLoader object at 0x000001D49B82B580>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x000001D49B837100>}, 'category': {'train': <torch.utils.data.dataloader.DataLoader object at 0x000001D49B837AC0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x000001D49B84CC70>}}, 'train_labels': <torch.utils.data.dataloader.DataLoader object at 0x000001D49B84CFD0>, 'test_labels': <torch.utils.data.dataloader.DataLoader object at 0x000001D49B85A100>, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "infile = './exports/hbs_result.pt'\n",
    "with open(infile,'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'company': {'train': <torch.utils.data.dataloader.DataLoader at 0x1ae9a57fd60>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x1ae9a48bf40>},\n",
       "  'brand': {'train': <torch.utils.data.dataloader.DataLoader at 0x1ae9a5d0be0>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x1ae9a5d01c0>},\n",
       "  'category': {'train': <torch.utils.data.dataloader.DataLoader at 0x1ae9a5d0e50>,\n",
       "   'test': <torch.utils.data.dataloader.DataLoader at 0x1ae9a5d0df0>}},\n",
       " 'train_labels': <torch.utils.data.dataloader.DataLoader at 0x1ae9a5d0820>,\n",
       " 'test_labels': <torch.utils.data.dataloader.DataLoader at 0x1ae9a5d03a0>,\n",
       " 'batch_size': 64}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader =data['data']['company']['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x1ae996b1910>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\82104\\Documents\\Mango_2\\adsf.ipynb ì…€ 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/82104/Documents/Mango_2/adsf.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mnext\u001b[39;49m(\u001b[39menumerate\u001b[39;49m(trainloader))\n",
      "File \u001b[1;32mc:\\Users\\82104\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\82104\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\82104\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\82104\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    204\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\82104\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[0;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\82104\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:169\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39m# array of string classes and object\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m np_str_obj_array_pattern\u001b[39m.\u001b[39msearch(elem\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mstr) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem\u001b[39m.\u001b[39mdtype))\n\u001b[0;32m    171\u001b[0m \u001b[39mreturn\u001b[39;00m collate([torch\u001b[39m.\u001b[39mas_tensor(b) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map)\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object"
     ]
    }
   ],
   "source": [
    "next(enumerate(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\82104\\Documents\\Mango_2\\adsf.ipynb ì…€ 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/82104/Documents/Mango_2/adsf.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainiter  \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(trainloader)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/82104/Documents/Mango_2/adsf.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mnext\u001b[39;49m(trainiter)\n",
      "File \u001b[1;32mc:\\Users\\82104\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\82104\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\82104\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\82104\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    204\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\82104\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[0;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\82104\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:169\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39m# array of string classes and object\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m np_str_obj_array_pattern\u001b[39m.\u001b[39msearch(elem\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mstr) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem\u001b[39m.\u001b[39mdtype))\n\u001b[0;32m    171\u001b[0m \u001b[39mreturn\u001b[39;00m collate([torch\u001b[39m.\u001b[39mas_tensor(b) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map)\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object"
     ]
    }
   ],
   "source": [
    "trainiter  = iter(trainloader)\n",
    "next(trainiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x1ae996d28b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pickle import dump\n",
    "import json\n",
    "from io import BytesIO\n",
    "import os \n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "\n",
    "class ShoppersDataset(Dataset):\n",
    "    \"\"\"\n",
    "        The class used to represent a given client's data set in VFL (no labels).\n",
    "\n",
    "        Attributes\n",
    "        __________\n",
    "        X: numpy.ndarray\n",
    "            A numppy array representing client's dataset. Each row represents a consumer's features.\n",
    "        \"\"\"\n",
    "    def __init__(self,X):\n",
    "        self.X = X\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index,:]\n",
    "    \n",
    "def create_train_test(df, train_index, test_index, batch_size, cols=None):\n",
    "    \"\"\"\n",
    "    Create train and test DataLoader objects using specified parameters.\n",
    "\n",
    "    Args:\n",
    "        df: pandas.DataFrame\n",
    "            DataFrame object containing data to be used for training and testing purposes.\n",
    "        cols: list\n",
    "            A subset of columns of `df` to include when creating train/test DataLoaders.\n",
    "        train_index: array-like\n",
    "            An iterable that contains indices representing training samples in `df`. \n",
    "        test_index: array-like\n",
    "            An iterable that contains indices representing testing samples in `df`. \n",
    "        batch_size: int\n",
    "            Batch size to use while training/testing models.\n",
    "    \n",
    "    Returns:\n",
    "        tuple(DataLoader)\n",
    "            A tuple that includes the train and test DataLoaders. \n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed=0)\n",
    "    \n",
    "    if cols != None:\n",
    "        train_ds = ShoppersDataset(\n",
    "            df.loc[train_index][cols].copy().to_numpy()\n",
    "        )\n",
    "        test_ds = ShoppersDataset(\n",
    "            df.loc[test_index][cols].copy().to_numpy()\n",
    "        )\n",
    "        train_dl = DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=False)\n",
    "        test_dl = DataLoader(dataset=test_ds, batch_size=batch_size, shuffle=False)\n",
    "        return train_dl,test_dl\n",
    "    else:\n",
    "        train_ds = ShoppersDataset(\n",
    "            df.loc[train_index].copy().to_numpy()\n",
    "        )\n",
    "        test_ds = ShoppersDataset(\n",
    "            df.loc[test_index].copy().to_numpy()\n",
    "        )\n",
    "        train_dl = DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=False)\n",
    "        test_dl = DataLoader(dataset=test_ds, batch_size=batch_size, shuffle=False)\n",
    "        return train_dl,test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n"
     ]
    }
   ],
   "source": [
    "cols = None\n",
    "if cols != None:\n",
    "    print('not none')\n",
    "else:\n",
    "    print('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pickle import dump\n",
    "import json\n",
    "from io import BytesIO\n",
    "import os \n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "\n",
    "data_filename = []\n",
    "data=[] \n",
    "with ZipFile('./data/hbs_dataset.zip', 'r') as zipObj:\n",
    "    listOfFileNames = zipObj.namelist()\n",
    "    for fileName in listOfFileNames:\n",
    "        if fileName.endswith('csv'): \n",
    "            # print(fileName)\n",
    "            zipRead = zipObj.read(fileName)\n",
    "            curr_df = pd.read_csv(BytesIO(zipRead))\n",
    "            data.append(curr_df)\n",
    "            data_filename.append(fileName)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C&gt;G</th>\n",
       "      <th>C[C&gt;G]G</th>\n",
       "      <th>C[C&gt;G]</th>\n",
       "      <th>[C&gt;G]G</th>\n",
       "      <th>T&gt;C</th>\n",
       "      <th>C[T&gt;C]G</th>\n",
       "      <th>C[T&gt;C]</th>\n",
       "      <th>[T&gt;C]G</th>\n",
       "      <th>T[T&gt;C]A</th>\n",
       "      <th>T[T&gt;C]</th>\n",
       "      <th>...</th>\n",
       "      <th>G[T&gt;G]G</th>\n",
       "      <th>G[T&gt;G]A</th>\n",
       "      <th>T[T&gt;G]C</th>\n",
       "      <th>C[C&gt;A]A</th>\n",
       "      <th>C[T&gt;G]T</th>\n",
       "      <th>A[T&gt;A]G</th>\n",
       "      <th>A[T&gt;G]A</th>\n",
       "      <th>C[T&gt;A]A</th>\n",
       "      <th>A[T&gt;A]A</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167778</td>\n",
       "      <td>0.572886</td>\n",
       "      <td>-0.202459</td>\n",
       "      <td>0.979088</td>\n",
       "      <td>0.278607</td>\n",
       "      <td>0.551523</td>\n",
       "      <td>0.872449</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>-0.388435</td>\n",
       "      <td>-0.193196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.939246</td>\n",
       "      <td>0.666221</td>\n",
       "      <td>-1.013557</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>-0.459210</td>\n",
       "      <td>-1.263353</td>\n",
       "      <td>-1.532208</td>\n",
       "      <td>-0.633714</td>\n",
       "      <td>0.149173</td>\n",
       "      <td>GGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.554365</td>\n",
       "      <td>1.286023</td>\n",
       "      <td>0.911996</td>\n",
       "      <td>0.443742</td>\n",
       "      <td>-0.090261</td>\n",
       "      <td>-1.552856</td>\n",
       "      <td>-0.951789</td>\n",
       "      <td>-1.003374</td>\n",
       "      <td>-0.140761</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483854</td>\n",
       "      <td>-0.883130</td>\n",
       "      <td>1.458533</td>\n",
       "      <td>-0.173843</td>\n",
       "      <td>-0.459210</td>\n",
       "      <td>-0.646080</td>\n",
       "      <td>1.014398</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>-0.934525</td>\n",
       "      <td>GGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013144</td>\n",
       "      <td>2.355728</td>\n",
       "      <td>1.469224</td>\n",
       "      <td>0.086845</td>\n",
       "      <td>0.043873</td>\n",
       "      <td>-0.851397</td>\n",
       "      <td>0.177501</td>\n",
       "      <td>-0.428218</td>\n",
       "      <td>0.106912</td>\n",
       "      <td>-0.193196</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.295021</td>\n",
       "      <td>1.182672</td>\n",
       "      <td>-0.024721</td>\n",
       "      <td>-1.092486</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>0.588467</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>1.188213</td>\n",
       "      <td>-0.212060</td>\n",
       "      <td>GGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.095586</td>\n",
       "      <td>-1.209955</td>\n",
       "      <td>0.726254</td>\n",
       "      <td>-0.270052</td>\n",
       "      <td>0.345673</td>\n",
       "      <td>0.726888</td>\n",
       "      <td>1.393660</td>\n",
       "      <td>-0.181722</td>\n",
       "      <td>-0.883782</td>\n",
       "      <td>-0.955097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>0.666221</td>\n",
       "      <td>-0.519139</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>-1.717321</td>\n",
       "      <td>1.205741</td>\n",
       "      <td>1.523719</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>-0.934525</td>\n",
       "      <td>GGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.322413</td>\n",
       "      <td>-0.140250</td>\n",
       "      <td>-0.202459</td>\n",
       "      <td>0.265294</td>\n",
       "      <td>0.412740</td>\n",
       "      <td>-0.500667</td>\n",
       "      <td>0.959318</td>\n",
       "      <td>0.064774</td>\n",
       "      <td>-0.388435</td>\n",
       "      <td>0.786390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128079</td>\n",
       "      <td>0.149771</td>\n",
       "      <td>0.964115</td>\n",
       "      <td>1.663443</td>\n",
       "      <td>2.057011</td>\n",
       "      <td>-0.646080</td>\n",
       "      <td>-0.513566</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>-0.934525</td>\n",
       "      <td>GGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>-1.997105</td>\n",
       "      <td>-1.209955</td>\n",
       "      <td>-1.316915</td>\n",
       "      <td>-1.519193</td>\n",
       "      <td>-1.465130</td>\n",
       "      <td>-0.149937</td>\n",
       "      <td>-1.559869</td>\n",
       "      <td>-1.332035</td>\n",
       "      <td>-0.140761</td>\n",
       "      <td>-0.846254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227696</td>\n",
       "      <td>-1.916032</td>\n",
       "      <td>-0.024721</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>-0.459210</td>\n",
       "      <td>0.588467</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>1.188213</td>\n",
       "      <td>-0.573292</td>\n",
       "      <td>BBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>-1.610519</td>\n",
       "      <td>-1.566523</td>\n",
       "      <td>-0.573945</td>\n",
       "      <td>-1.340744</td>\n",
       "      <td>-1.062729</td>\n",
       "      <td>-1.552856</td>\n",
       "      <td>-1.125526</td>\n",
       "      <td>-1.167705</td>\n",
       "      <td>-0.140761</td>\n",
       "      <td>0.242176</td>\n",
       "      <td>...</td>\n",
       "      <td>1.195404</td>\n",
       "      <td>2.215573</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>-1.088266</td>\n",
       "      <td>-0.028806</td>\n",
       "      <td>-0.513566</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>-0.934525</td>\n",
       "      <td>BBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.554365</td>\n",
       "      <td>-0.853387</td>\n",
       "      <td>-1.316915</td>\n",
       "      <td>0.979088</td>\n",
       "      <td>-1.062729</td>\n",
       "      <td>-1.377491</td>\n",
       "      <td>-0.778052</td>\n",
       "      <td>-0.346052</td>\n",
       "      <td>-0.883782</td>\n",
       "      <td>-0.737411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483854</td>\n",
       "      <td>-0.366680</td>\n",
       "      <td>-1.507974</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>-1.263353</td>\n",
       "      <td>0.505077</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>-0.934525</td>\n",
       "      <td>BBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>-1.146615</td>\n",
       "      <td>0.572886</td>\n",
       "      <td>-0.945430</td>\n",
       "      <td>-1.340744</td>\n",
       "      <td>-1.096263</td>\n",
       "      <td>-1.552856</td>\n",
       "      <td>-1.646737</td>\n",
       "      <td>-1.167705</td>\n",
       "      <td>1.345280</td>\n",
       "      <td>-0.193196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.939246</td>\n",
       "      <td>-0.883130</td>\n",
       "      <td>-0.024721</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>-1.088266</td>\n",
       "      <td>-0.646080</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>-1.544677</td>\n",
       "      <td>-0.212060</td>\n",
       "      <td>BBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.631682</td>\n",
       "      <td>-0.853387</td>\n",
       "      <td>-0.388202</td>\n",
       "      <td>-0.091604</td>\n",
       "      <td>-0.392061</td>\n",
       "      <td>-2.429681</td>\n",
       "      <td>-1.125526</td>\n",
       "      <td>-1.085539</td>\n",
       "      <td>0.354586</td>\n",
       "      <td>0.677547</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.295021</td>\n",
       "      <td>-0.883130</td>\n",
       "      <td>1.458533</td>\n",
       "      <td>1.663443</td>\n",
       "      <td>0.169845</td>\n",
       "      <td>1.205741</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>0.149173</td>\n",
       "      <td>BBB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C>G   C[C>G]G    C[C>G]    [C>G]G       T>C   C[T>C]G    C[T>C]  \\\n",
       "0    0.167778  0.572886 -0.202459  0.979088  0.278607  0.551523  0.872449   \n",
       "1    0.554365  1.286023  0.911996  0.443742 -0.090261 -1.552856 -0.951789   \n",
       "2    0.013144  2.355728  1.469224  0.086845  0.043873 -0.851397  0.177501   \n",
       "3    1.095586 -1.209955  0.726254 -0.270052  0.345673  0.726888  1.393660   \n",
       "4    0.322413 -0.140250 -0.202459  0.265294  0.412740 -0.500667  0.959318   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "595 -1.997105 -1.209955 -1.316915 -1.519193 -1.465130 -0.149937 -1.559869   \n",
       "596 -1.610519 -1.566523 -0.573945 -1.340744 -1.062729 -1.552856 -1.125526   \n",
       "597  0.554365 -0.853387 -1.316915  0.979088 -1.062729 -1.377491 -0.778052   \n",
       "598 -1.146615  0.572886 -0.945430 -1.340744 -1.096263 -1.552856 -1.646737   \n",
       "599  0.631682 -0.853387 -0.388202 -0.091604 -0.392061 -2.429681 -1.125526   \n",
       "\n",
       "       [T>C]G   T[T>C]A    T[T>C]  ...   G[T>G]G   G[T>G]A   T[T>G]C  \\\n",
       "0    0.146939 -0.388435 -0.193196  ... -0.939246  0.666221 -1.013557   \n",
       "1   -1.003374 -0.140761  0.133333  ...  0.483854 -0.883130  1.458533   \n",
       "2   -0.428218  0.106912 -0.193196  ... -1.295021  1.182672 -0.024721   \n",
       "3   -0.181722 -0.883782 -0.955097  ... -0.583471  0.666221 -0.519139   \n",
       "4    0.064774 -0.388435  0.786390  ...  0.128079  0.149771  0.964115   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "595 -1.332035 -0.140761 -0.846254  ... -0.227696 -1.916032 -0.024721   \n",
       "596 -1.167705 -0.140761  0.242176  ...  1.195404  2.215573  0.469697   \n",
       "597 -0.346052 -0.883782 -0.737411  ...  0.483854 -0.366680 -1.507974   \n",
       "598 -1.167705  1.345280 -0.193196  ... -0.939246 -0.883130 -0.024721   \n",
       "599 -1.085539  0.354586  0.677547  ... -1.295021 -0.883130  1.458533   \n",
       "\n",
       "      C[C>A]A   C[T>G]T   A[T>A]G   A[T>G]A   C[T>A]A   A[T>A]A  target  \n",
       "0    0.744800 -0.459210 -1.263353 -1.532208 -0.633714  0.149173     GGG  \n",
       "1   -0.173843 -0.459210 -0.646080  1.014398  0.277250 -0.934525     GGG  \n",
       "2   -1.092486  0.798900  0.588467 -0.004244  1.188213 -0.212060     GGG  \n",
       "3    0.744800 -1.717321  1.205741  1.523719  0.277250 -0.934525     GGG  \n",
       "4    1.663443  2.057011 -0.646080 -0.513566  0.277250 -0.934525     GGG  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "595  0.744800 -0.459210  0.588467 -0.004244  1.188213 -0.573292     BBB  \n",
       "596  0.744800 -1.088266 -0.028806 -0.513566  0.277250 -0.934525     BBB  \n",
       "597  0.744800  0.798900 -1.263353  0.505077  0.277250 -0.934525     BBB  \n",
       "598  0.744800 -1.088266 -0.646080 -0.004244 -1.544677 -0.212060     BBB  \n",
       "599  1.663443  0.169845  1.205741 -0.004244  0.277250  0.149173     BBB  \n",
       "\n",
       "[600 rows x 151 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>C&gt;G</th>\n",
       "      <th>C[C&gt;G]G</th>\n",
       "      <th>C[C&gt;G]</th>\n",
       "      <th>[C&gt;G]G</th>\n",
       "      <th>T&gt;C</th>\n",
       "      <th>C[T&gt;C]G</th>\n",
       "      <th>C[T&gt;C]</th>\n",
       "      <th>[T&gt;C]G</th>\n",
       "      <th>T[T&gt;C]A</th>\n",
       "      <th>...</th>\n",
       "      <th>G[T&gt;G]G</th>\n",
       "      <th>G[T&gt;G]A</th>\n",
       "      <th>T[T&gt;G]C</th>\n",
       "      <th>C[C&gt;A]A</th>\n",
       "      <th>C[T&gt;G]T</th>\n",
       "      <th>A[T&gt;A]G</th>\n",
       "      <th>A[T&gt;G]A</th>\n",
       "      <th>C[T&gt;A]A</th>\n",
       "      <th>A[T&gt;A]A</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GGG-0001</td>\n",
       "      <td>0.167778</td>\n",
       "      <td>0.572886</td>\n",
       "      <td>-0.202459</td>\n",
       "      <td>0.979088</td>\n",
       "      <td>0.278607</td>\n",
       "      <td>0.551523</td>\n",
       "      <td>0.872449</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>-0.388435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.939246</td>\n",
       "      <td>0.666221</td>\n",
       "      <td>-1.013557</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>-0.459210</td>\n",
       "      <td>-1.263353</td>\n",
       "      <td>-1.532208</td>\n",
       "      <td>-0.633714</td>\n",
       "      <td>0.149173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGG-0002</td>\n",
       "      <td>0.554365</td>\n",
       "      <td>1.286023</td>\n",
       "      <td>0.911996</td>\n",
       "      <td>0.443742</td>\n",
       "      <td>-0.090261</td>\n",
       "      <td>-1.552856</td>\n",
       "      <td>-0.951789</td>\n",
       "      <td>-1.003374</td>\n",
       "      <td>-0.140761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483854</td>\n",
       "      <td>-0.883130</td>\n",
       "      <td>1.458533</td>\n",
       "      <td>-0.173843</td>\n",
       "      <td>-0.459210</td>\n",
       "      <td>-0.646080</td>\n",
       "      <td>1.014398</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>-0.934525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GGG-0003</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>2.355728</td>\n",
       "      <td>1.469224</td>\n",
       "      <td>0.086845</td>\n",
       "      <td>0.043873</td>\n",
       "      <td>-0.851397</td>\n",
       "      <td>0.177501</td>\n",
       "      <td>-0.428218</td>\n",
       "      <td>0.106912</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.295021</td>\n",
       "      <td>1.182672</td>\n",
       "      <td>-0.024721</td>\n",
       "      <td>-1.092486</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>0.588467</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>1.188213</td>\n",
       "      <td>-0.212060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GGG-0005</td>\n",
       "      <td>1.095586</td>\n",
       "      <td>-1.209955</td>\n",
       "      <td>0.726254</td>\n",
       "      <td>-0.270052</td>\n",
       "      <td>0.345673</td>\n",
       "      <td>0.726888</td>\n",
       "      <td>1.393660</td>\n",
       "      <td>-0.181722</td>\n",
       "      <td>-0.883782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.583471</td>\n",
       "      <td>0.666221</td>\n",
       "      <td>-0.519139</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>-1.717321</td>\n",
       "      <td>1.205741</td>\n",
       "      <td>1.523719</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>-0.934525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GGG-0006</td>\n",
       "      <td>0.322413</td>\n",
       "      <td>-0.140250</td>\n",
       "      <td>-0.202459</td>\n",
       "      <td>0.265294</td>\n",
       "      <td>0.412740</td>\n",
       "      <td>-0.500667</td>\n",
       "      <td>0.959318</td>\n",
       "      <td>0.064774</td>\n",
       "      <td>-0.388435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128079</td>\n",
       "      <td>0.149771</td>\n",
       "      <td>0.964115</td>\n",
       "      <td>1.663443</td>\n",
       "      <td>2.057011</td>\n",
       "      <td>-0.646080</td>\n",
       "      <td>-0.513566</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>-0.934525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>BBB-0110</td>\n",
       "      <td>-1.997105</td>\n",
       "      <td>-1.209955</td>\n",
       "      <td>-1.316915</td>\n",
       "      <td>-1.519193</td>\n",
       "      <td>-1.465130</td>\n",
       "      <td>-0.149937</td>\n",
       "      <td>-1.559869</td>\n",
       "      <td>-1.332035</td>\n",
       "      <td>-0.140761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227696</td>\n",
       "      <td>-1.916032</td>\n",
       "      <td>-0.024721</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>-0.459210</td>\n",
       "      <td>0.588467</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>1.188213</td>\n",
       "      <td>-0.573292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>BBB-0126</td>\n",
       "      <td>-1.610519</td>\n",
       "      <td>-1.566523</td>\n",
       "      <td>-0.573945</td>\n",
       "      <td>-1.340744</td>\n",
       "      <td>-1.062729</td>\n",
       "      <td>-1.552856</td>\n",
       "      <td>-1.125526</td>\n",
       "      <td>-1.167705</td>\n",
       "      <td>-0.140761</td>\n",
       "      <td>...</td>\n",
       "      <td>1.195404</td>\n",
       "      <td>2.215573</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>-1.088266</td>\n",
       "      <td>-0.028806</td>\n",
       "      <td>-0.513566</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>-0.934525</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>BBB-0162</td>\n",
       "      <td>0.554365</td>\n",
       "      <td>-0.853387</td>\n",
       "      <td>-1.316915</td>\n",
       "      <td>0.979088</td>\n",
       "      <td>-1.062729</td>\n",
       "      <td>-1.377491</td>\n",
       "      <td>-0.778052</td>\n",
       "      <td>-0.346052</td>\n",
       "      <td>-0.883782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483854</td>\n",
       "      <td>-0.366680</td>\n",
       "      <td>-1.507974</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>-1.263353</td>\n",
       "      <td>0.505077</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>-0.934525</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>BBB-0199</td>\n",
       "      <td>-1.146615</td>\n",
       "      <td>0.572886</td>\n",
       "      <td>-0.945430</td>\n",
       "      <td>-1.340744</td>\n",
       "      <td>-1.096263</td>\n",
       "      <td>-1.552856</td>\n",
       "      <td>-1.646737</td>\n",
       "      <td>-1.167705</td>\n",
       "      <td>1.345280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.939246</td>\n",
       "      <td>-0.883130</td>\n",
       "      <td>-0.024721</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>-1.088266</td>\n",
       "      <td>-0.646080</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>-1.544677</td>\n",
       "      <td>-0.212060</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>BBB-0157</td>\n",
       "      <td>0.631682</td>\n",
       "      <td>-0.853387</td>\n",
       "      <td>-0.388202</td>\n",
       "      <td>-0.091604</td>\n",
       "      <td>-0.392061</td>\n",
       "      <td>-2.429681</td>\n",
       "      <td>-1.125526</td>\n",
       "      <td>-1.085539</td>\n",
       "      <td>0.354586</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.295021</td>\n",
       "      <td>-0.883130</td>\n",
       "      <td>1.458533</td>\n",
       "      <td>1.663443</td>\n",
       "      <td>0.169845</td>\n",
       "      <td>1.205741</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>0.149173</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0       C>G   C[C>G]G    C[C>G]    [C>G]G       T>C   C[T>C]G  \\\n",
       "0     GGG-0001  0.167778  0.572886 -0.202459  0.979088  0.278607  0.551523   \n",
       "1     GGG-0002  0.554365  1.286023  0.911996  0.443742 -0.090261 -1.552856   \n",
       "2     GGG-0003  0.013144  2.355728  1.469224  0.086845  0.043873 -0.851397   \n",
       "3     GGG-0005  1.095586 -1.209955  0.726254 -0.270052  0.345673  0.726888   \n",
       "4     GGG-0006  0.322413 -0.140250 -0.202459  0.265294  0.412740 -0.500667   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "595   BBB-0110 -1.997105 -1.209955 -1.316915 -1.519193 -1.465130 -0.149937   \n",
       "596   BBB-0126 -1.610519 -1.566523 -0.573945 -1.340744 -1.062729 -1.552856   \n",
       "597   BBB-0162  0.554365 -0.853387 -1.316915  0.979088 -1.062729 -1.377491   \n",
       "598   BBB-0199 -1.146615  0.572886 -0.945430 -1.340744 -1.096263 -1.552856   \n",
       "599   BBB-0157  0.631682 -0.853387 -0.388202 -0.091604 -0.392061 -2.429681   \n",
       "\n",
       "       C[T>C]    [T>C]G   T[T>C]A  ...   G[T>G]G   G[T>G]A   T[T>G]C  \\\n",
       "0    0.872449  0.146939 -0.388435  ... -0.939246  0.666221 -1.013557   \n",
       "1   -0.951789 -1.003374 -0.140761  ...  0.483854 -0.883130  1.458533   \n",
       "2    0.177501 -0.428218  0.106912  ... -1.295021  1.182672 -0.024721   \n",
       "3    1.393660 -0.181722 -0.883782  ... -0.583471  0.666221 -0.519139   \n",
       "4    0.959318  0.064774 -0.388435  ...  0.128079  0.149771  0.964115   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "595 -1.559869 -1.332035 -0.140761  ... -0.227696 -1.916032 -0.024721   \n",
       "596 -1.125526 -1.167705 -0.140761  ...  1.195404  2.215573  0.469697   \n",
       "597 -0.778052 -0.346052 -0.883782  ...  0.483854 -0.366680 -1.507974   \n",
       "598 -1.646737 -1.167705  1.345280  ... -0.939246 -0.883130 -0.024721   \n",
       "599 -1.125526 -1.085539  0.354586  ... -1.295021 -0.883130  1.458533   \n",
       "\n",
       "      C[C>A]A   C[T>G]T   A[T>A]G   A[T>G]A   C[T>A]A   A[T>A]A  target  \n",
       "0    0.744800 -0.459210 -1.263353 -1.532208 -0.633714  0.149173       1  \n",
       "1   -0.173843 -0.459210 -0.646080  1.014398  0.277250 -0.934525       1  \n",
       "2   -1.092486  0.798900  0.588467 -0.004244  1.188213 -0.212060       1  \n",
       "3    0.744800 -1.717321  1.205741  1.523719  0.277250 -0.934525       1  \n",
       "4    1.663443  2.057011 -0.646080 -0.513566  0.277250 -0.934525       1  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "595  0.744800 -0.459210  0.588467 -0.004244  1.188213 -0.573292       2  \n",
       "596  0.744800 -1.088266 -0.028806 -0.513566  0.277250 -0.934525       2  \n",
       "597  0.744800  0.798900 -1.263353  0.505077  0.277250 -0.934525       2  \n",
       "598  0.744800 -1.088266 -0.646080 -0.004244 -1.544677 -0.212060       2  \n",
       "599  1.663443  0.169845  1.205741 -0.004244  0.277250  0.149173       2  \n",
       "\n",
       "[600 rows x 152 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_code = {'RRR':0,'GGG':1,'BBB':2}\n",
    "data[0]['target'] = data[0]['target'].map(target_code)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, test_index = train_test_split(data[0].index.values,test_size=0.2,stratify=data[0]['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 86, 228, 460, 239,  55, 371, 331, 336,  44,  91, 235, 334,   5,\n",
       "        299, 461, 318,  33,  30, 113,  39, 314, 475, 309,  46, 528, 308,\n",
       "        117, 203, 253, 348, 595, 270, 373, 511, 266, 456, 260, 397, 134,\n",
       "        581, 245, 332, 558, 345, 473, 405,  89, 554, 139, 391, 280, 197,\n",
       "        105, 438, 455, 223, 279, 257,   3, 307, 111, 311, 130, 416, 453,\n",
       "        495, 118, 119, 286, 171, 501,  96, 285, 133, 363,  37,  50, 163,\n",
       "        327, 497, 249, 557, 269, 537, 292, 375, 244, 585, 417, 432,  71,\n",
       "        316, 400, 498, 578, 563, 593, 446, 582, 440, 381, 553,  14, 150,\n",
       "        386, 448,  22, 403, 457, 503, 229, 420, 571, 162, 272, 384, 409,\n",
       "        205, 521, 198,  13, 160, 243, 580, 298, 182, 520, 362, 462, 161,\n",
       "        143, 341, 212,   7, 479,  78, 555, 594, 493, 185, 301, 233, 358,\n",
       "        217,  77,  48, 158, 575, 522, 207, 566, 263, 512, 238, 447, 538,\n",
       "        221,  67,  79, 188, 174, 109,  32, 509, 196, 421, 523,  92, 599,\n",
       "        302, 506, 392, 531, 577, 339, 281, 399, 569, 452, 323, 123, 529,\n",
       "        546, 540,  19, 433, 176, 148, 236, 300, 587, 568, 186, 216, 387,\n",
       "        333, 152,  76, 204, 494, 376, 275,   9, 492, 468, 519, 471, 181,\n",
       "          0,  74, 211,  63,  57, 552, 222, 428, 146, 514, 232,  70, 408,\n",
       "        335, 258,   8, 505, 545, 356, 361,  11,  12, 378, 114,  51, 435,\n",
       "        430, 340, 206,  28, 106, 467,  23, 390, 502, 116, 192, 526, 489,\n",
       "        385, 262, 287,  84, 500, 338, 564, 463, 370, 175, 125, 402, 352,\n",
       "        156, 355,  56, 159, 136,  27, 295, 550,  17, 570, 485, 322, 572,\n",
       "         18, 477,  41, 436, 396, 177,  58, 140,  81, 598, 227, 294, 278,\n",
       "        305, 155, 132, 250, 224,  72, 104, 559, 169, 127, 164, 351, 108,\n",
       "        265, 122,  95, 231,  85, 534, 389,  68, 242,  87, 441,  42, 267,\n",
       "        388, 426, 360, 202,  20, 183, 259, 451, 273, 293, 343, 179, 193,\n",
       "        304, 583, 107, 524, 234, 219, 256, 120, 401, 518, 576, 246,  60,\n",
       "        126, 149, 496,  36, 100, 515, 504, 103, 592, 218,  38, 220, 330,\n",
       "        525, 291, 350, 353, 549, 591, 488, 337, 225,  47, 172, 380, 484,\n",
       "         82, 254, 539,  43, 200,  80, 499, 320, 562, 419, 101, 102, 541,\n",
       "        412, 588, 349, 377, 276, 414, 255, 567, 303, 589,  34, 121, 131,\n",
       "        560, 596, 190,  24, 153,  61,  90, 310, 579, 187,  40, 431, 450,\n",
       "        404, 382, 556, 383, 444, 469, 472, 157, 533, 326, 165, 283, 347,\n",
       "         62, 367,  65, 321, 407,  83, 464, 458, 527,  88, 312, 429,  97,\n",
       "        544,   6, 147, 466,  15, 306, 145, 284, 142, 415, 516, 251, 191,\n",
       "        478, 395, 138,  54, 144,  26, 507, 325, 543, 561, 487, 372, 268,\n",
       "        154, 481, 166,  35,  59, 128, 483, 584, 422,  98,  10, 199, 213,\n",
       "        597, 168,   2, 590, 551, 474, 374, 532, 508, 317, 329, 297],\n",
       "       dtype=int64),\n",
       " array([173, 586, 137, 241,  75,  64,  69, 565, 359, 393, 214, 437, 342,\n",
       "        230, 115, 124, 410, 129, 346, 368, 406, 379, 194,  16, 476, 425,\n",
       "        369, 535, 366, 439, 517, 491, 427, 443, 237, 271, 277, 288, 434,\n",
       "         94,  45, 482, 261, 264,  73, 365, 548, 141, 296,  25, 178,  52,\n",
       "        324, 465, 319, 413, 364, 290, 248,  31, 252, 445, 112, 454, 167,\n",
       "        210,   1,  29, 530, 490, 470,  93, 226, 189, 510, 480, 240, 513,\n",
       "        449, 398, 547, 274, 151,  99, 573, 574, 282, 411, 424, 418, 184,\n",
       "         21,  53,   4, 423, 135, 313, 215, 442, 247, 486, 344, 289, 354,\n",
       "        208, 536, 315, 459, 394,  49, 357, 328, 201, 170, 180,  66, 110,\n",
       "        542, 209, 195], dtype=int64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, test_labels = create_train_test(\n",
    "    df=data[0], train_index=train_index, test_index=test_index, batch_size=64, cols=['target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1d49ca7c610>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1d49ca7c6d0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2]])\n",
      "tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1]])\n",
      "tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]])\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0]])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1]])\n",
      "tensor([[2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]])\n",
      "tensor([[2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for data in train_labels:\n",
    "    print(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([56, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for data in test_labels:\n",
    "    print(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size, N, K = 256, 3, 3\n",
    "\n",
    "x = torch.rand(batch_size, N, K) # [M, N, K]\n",
    "y = torch.rand(batch_size, N, K) # [M, N, K]\n",
    "\n",
    "output1 = torch.cat([x,y], dim=1) #[M, N+N, K]\n",
    "output2 = torch.cat([x,y], dim=2) #[M, N, K+K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.0350e-01, 1.4899e-01, 4.7743e-01],\n",
       "         [9.4715e-01, 7.1139e-01, 8.0479e-01],\n",
       "         [1.0336e-01, 3.2935e-01, 7.2725e-01],\n",
       "         [7.5603e-01, 5.0983e-01, 6.5149e-01],\n",
       "         [4.2878e-01, 7.5607e-01, 1.3795e-02],\n",
       "         [4.1840e-02, 3.0173e-01, 5.3161e-01]],\n",
       "\n",
       "        [[4.5237e-01, 8.8837e-01, 1.4768e-01],\n",
       "         [2.0478e-02, 1.1304e-01, 2.4966e-01],\n",
       "         [8.5099e-01, 3.2564e-01, 2.5473e-01],\n",
       "         [9.9347e-01, 2.3294e-01, 1.6819e-01],\n",
       "         [2.4605e-01, 5.0966e-01, 5.0287e-01],\n",
       "         [1.6043e-01, 3.9312e-01, 4.2689e-01]],\n",
       "\n",
       "        [[4.8051e-01, 7.7709e-01, 2.9097e-03],\n",
       "         [3.8494e-01, 3.1591e-01, 1.7867e-01],\n",
       "         [3.4842e-01, 4.5304e-01, 5.5520e-02],\n",
       "         [9.7999e-02, 3.1484e-01, 1.0359e-02],\n",
       "         [2.5829e-02, 8.5811e-01, 7.6582e-01],\n",
       "         [8.6752e-01, 5.4237e-01, 9.4450e-04]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[9.1199e-01, 1.3941e-01, 7.0780e-01],\n",
       "         [1.0556e-01, 8.6896e-01, 6.7687e-01],\n",
       "         [8.0777e-02, 9.2459e-01, 8.0129e-01],\n",
       "         [1.6094e-01, 1.6096e-01, 7.4417e-02],\n",
       "         [8.7225e-01, 4.8137e-01, 8.4339e-01],\n",
       "         [1.3036e-01, 8.1867e-01, 4.7675e-01]],\n",
       "\n",
       "        [[9.3115e-01, 5.4654e-01, 9.8474e-02],\n",
       "         [6.1230e-01, 7.2782e-01, 6.9435e-01],\n",
       "         [8.2973e-01, 3.2885e-01, 3.4192e-01],\n",
       "         [8.7069e-01, 7.2738e-01, 4.5693e-01],\n",
       "         [7.9012e-01, 3.3565e-01, 5.7893e-01],\n",
       "         [5.7096e-01, 5.0902e-01, 4.5127e-01]],\n",
       "\n",
       "        [[4.2434e-01, 7.3791e-04, 9.5879e-01],\n",
       "         [9.8744e-01, 5.4781e-01, 5.3256e-01],\n",
       "         [2.1580e-01, 1.5883e-01, 8.3125e-01],\n",
       "         [9.1144e-01, 5.6518e-01, 1.6491e-01],\n",
       "         [7.8545e-01, 1.6689e-01, 8.3635e-01],\n",
       "         [9.6234e-01, 3.1895e-01, 5.9972e-01]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.0350e-01, 1.4899e-01, 4.7743e-01, 7.5603e-01, 5.0983e-01,\n",
       "          6.5149e-01],\n",
       "         [9.4715e-01, 7.1139e-01, 8.0479e-01, 4.2878e-01, 7.5607e-01,\n",
       "          1.3795e-02],\n",
       "         [1.0336e-01, 3.2935e-01, 7.2725e-01, 4.1840e-02, 3.0173e-01,\n",
       "          5.3161e-01]],\n",
       "\n",
       "        [[4.5237e-01, 8.8837e-01, 1.4768e-01, 9.9347e-01, 2.3294e-01,\n",
       "          1.6819e-01],\n",
       "         [2.0478e-02, 1.1304e-01, 2.4966e-01, 2.4605e-01, 5.0966e-01,\n",
       "          5.0287e-01],\n",
       "         [8.5099e-01, 3.2564e-01, 2.5473e-01, 1.6043e-01, 3.9312e-01,\n",
       "          4.2689e-01]],\n",
       "\n",
       "        [[4.8051e-01, 7.7709e-01, 2.9097e-03, 9.7999e-02, 3.1484e-01,\n",
       "          1.0359e-02],\n",
       "         [3.8494e-01, 3.1591e-01, 1.7867e-01, 2.5829e-02, 8.5811e-01,\n",
       "          7.6582e-01],\n",
       "         [3.4842e-01, 4.5304e-01, 5.5520e-02, 8.6752e-01, 5.4237e-01,\n",
       "          9.4450e-04]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[9.1199e-01, 1.3941e-01, 7.0780e-01, 1.6094e-01, 1.6096e-01,\n",
       "          7.4417e-02],\n",
       "         [1.0556e-01, 8.6896e-01, 6.7687e-01, 8.7225e-01, 4.8137e-01,\n",
       "          8.4339e-01],\n",
       "         [8.0777e-02, 9.2459e-01, 8.0129e-01, 1.3036e-01, 8.1867e-01,\n",
       "          4.7675e-01]],\n",
       "\n",
       "        [[9.3115e-01, 5.4654e-01, 9.8474e-02, 8.7069e-01, 7.2738e-01,\n",
       "          4.5693e-01],\n",
       "         [6.1230e-01, 7.2782e-01, 6.9435e-01, 7.9012e-01, 3.3565e-01,\n",
       "          5.7893e-01],\n",
       "         [8.2973e-01, 3.2885e-01, 3.4192e-01, 5.7096e-01, 5.0902e-01,\n",
       "          4.5127e-01]],\n",
       "\n",
       "        [[4.2434e-01, 7.3791e-04, 9.5879e-01, 9.1144e-01, 5.6518e-01,\n",
       "          1.6491e-01],\n",
       "         [9.8744e-01, 5.4781e-01, 5.3256e-01, 7.8545e-01, 1.6689e-01,\n",
       "          8.3635e-01],\n",
       "         [2.1580e-01, 1.5883e-01, 8.3125e-01, 9.6234e-01, 3.1895e-01,\n",
       "          5.9972e-01]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower_env",
   "language": "python",
   "name": "flower_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
